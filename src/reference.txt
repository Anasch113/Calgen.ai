https://www.sembly.ai/pricing/?hsa_acc=4188702770&hsa_cam=15106251293&hsa_grp=138622114303&hsa_ad=636057143258&hsa_src=s&hsa_tgt=dsa-1431605133110&hsa_kw=&hsa_mt=&hsa_net=adwords&hsa_ver=3&gad_source=2

https://docs.google.com/spreadsheets/d/1eF7MQAuIac2mMs-jbWL1iOnYAFO_o8pS/edit?usp=sharing&ouid=103869236222874156758&rtpof=true&sd=true



https://demo.1capapp.com/demo


text-[#4D5EC3]
bg-[#4D5EC3]
bg-[#d8ddf9]


text-[#B443B0]
bg-[#B443B0]
bg-[#f9e4f8]


<button onClick={() => checkout("business")} className='font-poppins bg-[#B443B0]  py-3 px-3 rounded-3xl w-44 text-white hover:bg-[#5b70e7]'>
                    Get Now
                </button>


                


https://turboscribe.ai/?ref=bng-2023-11-29&msclkid=23f82b822b04129e93874d8417961a86

https://docs.rev.ai/api/alignment/get-started/



https://quiet-raindrop-c438cb.netlify.app/

Pre-Transcript File Idea :-


I mean the functionality for a user to upload a checked transcript for editing and output to srt file. So they can download raw text, edit it themselves outside the platform if they want to using their own transcription playback software they might have already.  And then go back to the job and replace the raw text with their edited text. And then have captify retime the file and then allow them to download an srt file. This is the key part of the gate.



 Let say we have a database already and we have make a transcript for a particular video.


So once I visit the transcription page I will click on the the history I have done before and it opens. Then the whole transcription that we have before can be deleted and I will replace it with new one. The one I deleted will be same like the new one I will paste but there will be little corrections.


I now want the you to do the word alignment where by the video will be playing and it will be marking the section on the words which is tally to what they saying in the video.

Then after that we will now create an srt for the transcription
The reason why we are pasting the new one is because the human transcription is more accurate than that of AI 


So there may be some error in that of AI that is why I am replacing it with mine and creating an srt

















                  {isOpen && (
          <div className="absolute mt-16  w-48 h-48  bg-white border border-gray-200 shadow-md rounded-lg z-10">
            <a className="block px-4 py-3 text-sm border-b text-gray-600 hover:bg-gray-100" href="user-profile">Profile</a>
            <a className="block px-4 py-3 text-sm border-b text-gray-600 hover:bg-gray-100" href="#">Payment Info</a>
          
           
            {/* Add more options here */}
          </div>
        )}
        {/* Close dropdown when clicking outside */}
        {isOpen && <div className="fixed inset-0 z-0" onClick={closeDropdown}></div>}












           <div className="  w-full  p-5 mt-5">

                        <h1 className='text-3xl font-semibold font-roboto text-text-color-blue '>Transcription Text</h1>

                        <div className='w-full my-5  border '></div>

                        <div className='flex justify-end gap-7'>
                            {
                                transcribeText && <button disabled={isDownloadingtr} className=" hover:bg-blue-500 text-white bg-bg-blue py-4 px-5 rounded-full w-fit" onClick={() => {
                                    if (selectedFormat === "SRT") {
                                        downloadSrtFile();
                                    } else {
                                        downloadPdf();
                                    }
                                }}>

                                    <span className="flex items-center gap-1 font-poppins">
                                        {
                                            !isDownloadingtr ? (<IoCloudDownloadSharp size={25} />) : (<div className='spinner'></div>)
                                        }
                                    </span>
                                </button>
                            }
                            {
                                transcribeText && <button className=" hover:bg-blue-500 text-white bg-bg-blue py-4 px-5 rounded-full w-fit" onClick={toggleModal}>

                                    <span className="flex items-center gap-1 font-poppins "> <FaExchangeAlt size={25} />  </span>
                                </button>
                            }
                        </div>

                        {
                            showFormatModal && <FormatModal

                                showFormatModal={showFormatModal}
                                selectedFormat={selectedFormat}
                                isDefault={isDefault}
                                toggleModal={toggleModal}
                                handleFormatChange={handleFormatChange}
                                handleSetDefaultChange={handleSetDefaultChange}
                                handleContinue={handleContinue}
                            />
                        }

                        <div ref={contentRef} className='w-full p-5 min-h-[450px] mt-5'>
                            {
                                transcribeText && selectedFormat2 === "standard" ? (transcribeText) :
                                    transcribeText && (subtitle.split('\n').map((subtitle, index) => (
                                        <p className='py-2' key={index}>{subtitle}</p>
                                    )))

                            }

                        </div>

                    </div>










                    
  const calculateHighlightedIndex = (currentTime) => {
    console.log(currentTime)
    // Get the transcript text from the transcriptions state
    const transcriptText = transcriptions.text;

    // Split the transcript text into individual sentences or segments
    const segments = transcriptText.split('. ');

    // Initialize variables to keep track of the current position in the audio and the index of the matched segment
    let currentPosition = 0;
    let matchedIndex = null;

    // Iterate through each segment to find the one that matches the current time
    for (let i = 0; i < segments.length; i++) {
      // Calculate the duration of the current segment based on the number of characters
      const segmentDuration = segments[i].length;

      // Check if the current time falls within the duration of this segment
      if (currentTime >= currentPosition && currentTime < currentPosition + segmentDuration) {
        // If matched, set the matchedIndex and break the loop
        matchedIndex = i;
        break;
      }

      // Move the currentPosition to the end of the current segment
      currentPosition += segmentDuration + 2; // Add 2 to account for the period and space after each segment
    }

    // Return the index of the matched segment
    return matchedIndex;
  };















   const calculateHighlightedIndex = (currentTime) => {
    // Get the transcript text from the transcriptions state
    const transcriptText = transcriptions.text;
  
    // Split the transcript text into individual words
    const words = transcriptText.split(' ');
  
    // Initialize matchedIndex to null
    let matchedIndex = null;
  
    // Initialize currentPosition to keep track of the current position in the audio
    let currentPosition = 0;
  
    // Iterate through each word to find the one that matches the current time
    for (let i = 0; i < words.length; i++) {
      // Calculate the duration of the current word based on an average word length (you may need to adjust this based on your actual data)
      const wordDuration = 0.5; // Assuming an average word length of 0.5 seconds
  
      // Check if the current time falls within the duration of this word
      if (currentTime >= currentPosition && currentTime < currentPosition + wordDuration) {
        // If matched, set the matchedIndex and break the loop
        matchedIndex = i;
        break;
      }
  
      // Move the currentPosition to the end of the current word
      currentPosition += wordDuration;
    }
  
    // Return the index of the matched word
    console.log("match index", matchedIndex)
    setWordsIndex(matchedIndex)
    return matchedIndex;
  };